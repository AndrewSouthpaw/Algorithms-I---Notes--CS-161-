Week 5







=====================================================================
Section 11 - Dijkstra's Shortest-Path Algorithm
=====================================================================


/////////////////////////////////////////////////////////////////////
11.1 - Dijkstra's Shortest Path Algorithm
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\



Single-Source shortest paths
=======================================
Input: directed graph (G=(V,E)). m = |E|, n = |V|
- each edge has nonnegative length l_e
- source vertex s
Output: for each v in V, compute L(v) = length of shortest s-v path in G
Assumptions:
	1. f.a. v in V, t.e. an s -> v path
	2. l_e >= 0 f.a. e in E


BFS only computes shortest path if l_e = 1 for every edge e
Question: why not replace each edge e by directed path of l_e unit length edges
Answer: blows up graph too much. Lengths could be 100, 1000, etc.
		Too wasteful.







Dijkstra's Algorithm
=======================================
Initialize:
	- X = {S} // vertices processed so far
	- A[S] = 0	// shortest path distances
	- B[S] = empty path 	// computed shortest path
							// not actually used in implementation, for 
							// learning

Main Loop
	- while X != V:		// grow X by one node into world unexplored
		- among all edges (v,w) in E with v in X, w not in X, pick
		  pick one that minimizes A[v] + l_vw	(Dijkstra's greedy criterion)
		  	// call it (v*,w*)
		  	// looking at edges with tail in known sphere and head in unknown
		- add w* to X
		- set A[w*] = A[v*] + l_v*w*
		- set B[w*] = B[w*] u (v*,w*)







/////////////////////////////////////////////////////////////////////
11.2 - Example
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\


Sucking nodes into the world of explored nodes, and then looking at all
subsequent nodes and their "greedy score"


Non-Example -- with negative lengths
=======================================
Question: why not reduce computing shortest paths with negative edge lengths
to same problem with nonnegative edge lengths (by adding large constant to
edge lengths)
Problem: doesn't preserve shortest paths! 
		path one: 1, -5	 (shortest)		=> 6, 0
		path two: -2					=> 3	(shortest)
		
Also: Dijkstra's algorithm incorrect, getting messed up by the greedy score
That's the trouble with being greedy... :)












/////////////////////////////////////////////////////////////////////
11.3 - Correctness Proof
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\


Theorem: for every directed graph with nonnegative edge lengths, Dijkstra's
algorithm computes all shortest-path distances
	A[v] = L(v) f.a. v in V
	        ^-- true shortest path

Proof: by induction on number of iterations
Base case: A[s] = L(s) = 0
Inductive step:
Inductive hypothesis: all previous iterations correct
	f.a. v in X, A[v] = L(v) and
				 B[v] is true shortest s-v path in G

In current iteration:
	We pick edge (v*,w*) and add w* to X
	We set B[w*] = B[v*] u (v*,w*)
L(v*)+l_v*w*--^		^-- has length by L(v*)
	Also: A[w*] = A[v*] + l_v*w* = L(v*) + l_v*w*

Upshot:
	in current iteration, we set:
	1. A[w*] = L(v*) + l_v*w*	// output of path to w* is true shortest path 
								// to v* + length v* to w*
	2. B[w*] = bonafide path from s to w* with length above

To finish proof: show that every s-w* path has
	length >= L(v*) + l_v*w*  (if so, our path is the shortest)
	
So let P = any path s->w* path
Every path s->w* has to cross frontier at least once
	s in X, w* not in x. "cross the frontier"
and so has form  s -> y -> (frontier) -> z -> w*
				prefix    direct edge     suffix

	l_yz
	l_zw* >= 0 (no negative edges)
	l_sy is some path to y, therefore >= length of shortest s-y path
										 (inductive hypothesis)
		 = L(y) = A[y] by inductive hypothesis

Total length of path P: >= A[y] + l_yz + 0
=> by Dijkstra's greedy criterion, A[v*] + l_v*w* <= A[y] + l_yz
  length of our path <= length of competing path P
  because we choose the path with the best greedy score















/////////////////////////////////////////////////////////////////////
11.4 - Implementation and Running Time of Dijkstra's
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\


Naive implementation running time: TH(mn)
	- (n-1) iterations of while loop
	- linear scan through all edges
	- TH(m) work per iteration, TH(1) work per edge


Heap Operations
=======================================
Question: we're doing minimum scans repeatedly, is there a way to keep it 
around?
Heap property: at every node, key <= children's keys
- perfectly balanced binary tree (height ~= log(base2)(n) )
- extractMin by swapping up last leaf, bubbling down
- insert via bubbling up
- delete from middle (bubble up or down as needed)



Invariants
=======================================
Invariant 1: elements in heap = vertices of V-X
Invariant 2: for v n.i. X, key [v] = smallest Dijkstra greedy score of an edge
									 (u,v) in E with u in X
									 (+INF if no such edge exist)

Point: by invariants, extractMin yields correct vertex w* to add to X next





Maintaining the invariants
=======================================
When you add a new vertex into X, you'll need to update the keys that go out
from w

when w extracted from heap
- for each edge (w,v) in E:
	- if v in V-X (i.e. in heap)
		// key update
		- delete v from heap
		- recompute key[v] = min{key[v], A[w]+l_wv}
		- reinsert v into heap


Run-time: dominated by heap operations. (O(log n) each)
- (n-1) extractMins
- each edge (v,w) triggers at most one Delete/Insert combo 
	(if v added to X first)
  (as opposed to vertex-centric view)
So: # of heap operations is O(n+m) = O(m)  (since m dominates n, weakly connected)
So: running time = O(m log n)   (like sorting)




















=====================================================================
Section 12 - Heaps
=====================================================================
















/////////////////////////////////////////////////////////////////////
12.1 - Data structures overview
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\


Purpose: organize data so it can be accessed quickly and usefully
Ex: lists, stacks, queues, heaps, search trees, hash tables, bloom filters,
	union-find, etc.
different data structures support different sets of operations
Rule of thumb: choose "minimal" data structure that supports all the
			   operations you need, and no more.


Data structure levels
	Level 0 = "what's a data structure?"
	Level 1 = cocktail party awareness
	Level 2 = comfortable using them as client, good sense of what is suitable
	Level 3 = understands how they are implemented














/////////////////////////////////////////////////////////////////////
12.2 - Heaps - Operations and Applications
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\


- a container for objects that have keys
	- employer records, network edges, events, etc.

Insert: add new object to heap
	[O(log n)]
Extract-min: remove object in heap with minimum key value
		     [ties broken arbitrarily, also possible extract-max]
	[O(log n) - n = # objects in heap]

HEAPIFY(n batched inserts in O(n) time), Delete (O(log n) time)



Application: sorting
=======================================
Canonical use of heap: fast way to do repeated minimum computations
Example: SelectionSort => O(n^2) 
HeapSort: insert elements, then extract mins => O(n log n)
		  => optimal for "comparison-based" sorting algorithm
		  => pretty damn close to quicksort



Application: Event Manager
=======================================
"Priority Queue" - synonym for heap
Example: simulation (e.g. for a video game)
	- objects = event records [action/update to occur at given time in future]
	- keys = time event scheduled to occur
	- Extract-Min => yields the next scheduled event




Application: Median Maintenance
=======================================
I give you: sequence x1,...,xn of numbers, one-by-one
You tell me: at each time step i, the median of the set
Constraint: use O(log i) time at each step i.
Solution: maintain heaps H_low : support extractMax
						 H_high: support extractMin
Maintain invariant that 1/2 smallest (largest) elements in H_low (H_high)
You check: 
	1. can maintain invariant with O(log i) work
	2. given invariant, can compute median in O(log i) work

Can maintain balance 50/50 split




Application: Speeding up Dijkstra
=======================================
- naivie implementation: O(nm) -- # loop it * linear scan for min comp
- with heads -> run time O(m log n)


























































